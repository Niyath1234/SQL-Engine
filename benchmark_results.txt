warning: unused import: `arrow::datatypes::*`
 --> src/storage/fragment.rs:2:5
  |
2 | use arrow::datatypes::*;
  |     ^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: unused import: `FragmentMetadata`
 --> src/storage/compression.rs:1:65
  |
1 | use crate::storage::fragment::{ColumnFragment, CompressionType, FragmentMetadata};
  |                                                                 ^^^^^^^^^^^^^^^^

warning: unused import: `arrow::array::*`
 --> src/storage/compression.rs:2:5
  |
2 | use arrow::array::*;
  |     ^^^^^^^^^^^^^^^

warning: unused import: `arrow::datatypes::*`
 --> src/storage/compression.rs:3:5
  |
3 | use arrow::datatypes::*;
  |     ^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/storage/compression.rs:4:5
  |
4 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `std::hash::Hash`
 --> src/storage/factorized.rs:5:5
  |
5 | use std::hash::Hash;
  |     ^^^^^^^^^^^^^^^

warning: unused import: `FragmentMetadata`
 --> src/storage/adaptive_fragment.rs:3:48
  |
3 | use crate::storage::fragment::{ColumnFragment, FragmentMetadata, CompressionType};
  |                                                ^^^^^^^^^^^^^^^^

warning: unused import: `MemoryTier`
 --> src/storage/adaptive_fragment.rs:4:35
  |
4 | use crate::storage::memory_tier::{MemoryTier, FragmentAccessStats};
  |                                   ^^^^^^^^^^

warning: unused import: `crate::hypergraph::node::NodeId`
 --> src/storage/adaptive_fragment.rs:5:5
  |
5 | use crate::hypergraph::node::NodeId;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `HashLearnedIndex`
 --> src/storage/tiered_index.rs:4:58
  |
4 | use crate::storage::learned_index::{RecursiveModelIndex, HashLearnedIndex, LearnedIndex};
  |                                                          ^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/storage/tiered_index.rs:9:5
  |
9 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `PathCache`
 --> src/hypergraph/graph.rs:3:50
  |
3 | use crate::hypergraph::path::{HyperPath, PathId, PathCache, PathSignature};
  |                                                  ^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/hypergraph/node.rs:3:5
  |
3 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `HyperNode`
 --> src/hypergraph/coarsening.rs:4:31
  |
4 | use crate::hypergraph::node::{HyperNode, NodeId};
  |                               ^^^^^^^^^

warning: unused import: `HyperEdge`
 --> src/hypergraph/coarsening.rs:5:31
  |
5 | use crate::hypergraph::edge::{HyperEdge, EdgeId};
  |                               ^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/hypergraph/coarsening.rs:7:5
  |
7 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `std::collections::HashMap`
 --> src/query/plan.rs:5:5
  |
5 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::query::parser::ParsedQuery`
 --> src/query/cte.rs:5:5
  |
5 | use crate::query::parser::ParsedQuery;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::hypergraph::node::NodeId`
 --> src/query/cte.rs:7:5
  |
7 | use crate::hypergraph::node::NodeId;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::storage::fragment::Value`
 --> src/query/functions.rs:3:5
  |
3 | use crate::storage::fragment::Value;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `anyhow::Result`
 --> src/query/functions.rs:5:5
  |
5 | use anyhow::Result;
  |     ^^^^^^^^^^^^^^

warning: unused import: `crate::query::expression`
 --> src/query/parser_enhanced.rs:3:5
  |
3 | use crate::query::expression;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Context`
 --> src/query/parser_enhanced.rs:5:22
  |
5 | use anyhow::{Result, Context};
  |                      ^^^^^^^

warning: ambiguous glob re-exports
  --> src/query/mod.rs:15:9
   |
15 | pub use parser::*;
   |         ^^^^^^^^^ the name `JoinType` in the type namespace is first re-exported here
16 | pub use planner::*;
17 | pub use plan::*;
   |         ------- but the name `JoinType` in the type namespace is also re-exported here
   |
   = note: `#[warn(ambiguous_glob_reexports)]` on by default

warning: ambiguous glob re-exports
  --> src/query/mod.rs:15:9
   |
15 | pub use parser::*;
   |         ^^^^^^^^^ the name `AggregateFunction` in the type namespace is first re-exported here
16 | pub use planner::*;
17 | pub use plan::*;
   |         ------- but the name `AggregateFunction` in the type namespace is also re-exported here

warning: unused import: `std::sync::Arc`
 --> src/execution/engine.rs:6:5
  |
6 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused imports: `FragmentPredicate` and `can_prune_fragment`
 --> src/execution/operators.rs:8:36
  |
8 | use crate::storage::cache_layout::{can_prune_fragment, FragmentPredicate};
  |                                    ^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/execution/batch.rs:4:5
  |
4 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `crate::hypergraph::node::NodeId`
 --> src/execution/wcoj.rs:4:5
  |
4 | use crate::hypergraph::node::NodeId;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::hypergraph::edge::EdgeId`
 --> src/execution/wcoj.rs:5:5
  |
5 | use crate::hypergraph::edge::EdgeId;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `AtomicBool`
 --> src/execution/adaptive.rs:6:38
  |
6 | use std::sync::atomic::{AtomicUsize, AtomicBool, Ordering};
  |                                      ^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/execution/result.rs:8:5
  |
8 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/execution/having.rs:7:5
  |
7 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `crate::hypergraph::node::NodeId`
 --> src/incremental/propagator.rs:3:5
  |
3 | use crate::hypergraph::node::NodeId;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> src/incremental/version.rs:2:5
  |
2 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `HashSet`
 --> src/distributed/sharding.rs:6:33
  |
6 | use std::collections::{HashMap, HashSet};
  |                                 ^^^^^^^

warning: unused import: `crate::execution::wcoj::should_use_wcoj`
  --> src/engine.rs:16:5
   |
16 | use crate::execution::wcoj::should_use_wcoj;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Hasher`
 --> src/storage/fragment.rs:6:23
  |
6 | use std::hash::{Hash, Hasher};
  |                       ^^^^^^

warning: unused import: `Hash`
 --> src/storage/fragment.rs:6:17
  |
6 | use std::hash::{Hash, Hasher};
  |                 ^^^^

warning: unused import: `bitvec::prelude`
 --> src/storage/learned_index.rs:4:5
  |
4 | use bitvec::prelude::*;
  |     ^^^^^^^^^^^^^^^

warning: unused import: `BatchIterator`
 --> src/execution/engine.rs:2:47
  |
2 | use crate::execution::batch::{ExecutionBatch, BatchIterator};
  |                                               ^^^^^^^^^^^^^

warning: unused import: `arrow::array`
 --> src/execution/batch.rs:2:5
  |
2 | use arrow::array::*;
  |     ^^^^^^^^^^^^

warning: unused import: `rayon::prelude`
 --> src/execution/engine.rs:7:5
  |
7 | use rayon::prelude::*;
  |     ^^^^^^^^^^^^^^

warning: unused variable: `mmap`
   --> src/storage/fragment.rs:227:25
    |
227 |         if let Some(ref mmap) = self.mmap {
    |                         ^^^^ help: if this is intentional, prefix it with an underscore: `_mmap`
    |
    = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `right_nested`
   --> src/storage/factorized.rs:195:21
    |
195 |         if let Some(right_nested) = right.get_nested(left_root) {
    |                     ^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_right_nested`

warning: unused variable: `join_key`
   --> src/storage/factorized.rs:188:5
    |
188 |     join_key: usize, // Index of join key in root_values
    |     ^^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
188 |     _join_key: usize, // Index of join key in root_values
    |     +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
188 -     join_key: usize, // Index of join key in root_values
188 +     execution::simd_kernels::SIMD_LANES: usize, // Index of join key in root_values
    |

warning: variable does not need to be mutable
   --> src/storage/factorized.rs:197:17
    |
197 |             let mut nested = FactorizedRelation::new_nested(vec![]);
    |                 ----^^^^^^
    |                 |
    |                 help: remove this `mut`
    |
    = note: `#[warn(unused_mut)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `column_name`
   --> src/storage/cache_layout.rs:112:58
    |
112 |     pub fn build_fragments(&self, array: Arc<dyn Array>, column_name: &str) -> Vec<ColumnFragment> {
    |                                                          ^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_column_name`

warning: value assigned to `distinct_count` is never read
   --> src/storage/cache_layout.rs:221:17
    |
221 |         let mut distinct_count = 0;
    |                 ^^^^^^^^^^^^^^
    |
    = help: maybe it is overwritten before being read?
    = note: `#[warn(unused_assignments)]` (part of `#[warn(unused)]`) on by default

warning: variable does not need to be mutable
   --> src/storage/cache_layout.rs:328:13
    |
328 |         let mut vec = Vec::with_capacity(size);
    |             ----^^^
    |             |
    |             help: remove this `mut`

warning: variable does not need to be mutable
   --> src/storage/memory_tier.rs:339:13
    |
339 |         let mut to_promote: Vec<NodeId> = self.prefetch_queue.iter().map(|n| *n).collect();
    |             ----^^^^^^^^^^
    |             |
    |             help: remove this `mut`

warning: unused variable: `tables`
  --> src/hypergraph/path.rs:74:33
   |
74 |     pub fn covers_tables(&self, tables: &[String]) -> bool {
   |                                 ^^^^^^ help: if this is intentional, prefix it with an underscore: `_tables`

warning: variable does not need to be mutable
   --> src/hypergraph/coarsening.rs:241:13
    |
241 |         let mut processed: HashSet<EdgeId> = HashSet::new();
    |             ----^^^^^^^^^
    |             |
    |             help: remove this `mut`

warning: unused variable: `expr`
   --> src/query/parser.rs:174:53
    |
174 |             sqlparser::ast::SelectItem::UnnamedExpr(expr) => {
    |                                                     ^^^^ help: if this is intentional, prefix it with an underscore: `_expr`

warning: unused variable: `expr`
   --> src/query/parser.rs:177:57
    |
177 |             sqlparser::ast::SelectItem::ExprWithAlias { expr, alias } => {
    |                                                         ^^^^ help: try ignoring the field: `expr: _`

warning: unused variable: `join`
   --> src/query/parser.rs:196:13
    |
196 |         for join in &item.joins {
    |             ^^^^ help: if this is intentional, prefix it with an underscore: `_join`

warning: variable does not need to be mutable
   --> src/query/parser.rs:193:9
    |
193 |     let mut joins = vec![];
    |         ----^^^^^
    |         |
    |         help: remove this `mut`

warning: unused variable: `where_clause`
   --> src/query/parser.rs:207:17
    |
207 |     if let Some(where_clause) = &select.selection {
    |                 ^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_where_clause`

warning: variable does not need to be mutable
   --> src/query/parser.rs:205:9
    |
205 |     let mut filters = vec![];
    |         ----^^^^^^^
    |         |
    |         help: remove this `mut`

warning: unused variable: `item`
   --> src/query/parser.rs:217:9
    |
217 |     for item in &select.projection {
    |         ^^^^ help: if this is intentional, prefix it with an underscore: `_item`

warning: variable does not need to be mutable
   --> src/query/parser.rs:215:9
    |
215 |     let mut aggregates = vec![];
    |         ----^^^^^^^^^^
    |         |
    |         help: remove this `mut`

warning: unused variable: `limit`
   --> src/query/parser.rs:261:17
    |
261 |     if let Some(limit) = &query.limit {
    |                 ^^^^^ help: if this is intentional, prefix it with an underscore: `_limit`

warning: unused variable: `join`
   --> src/query/planner.rs:113:13
    |
113 |         for join in joins {
    |             ^^^^ help: if this is intentional, prefix it with an underscore: `_join`

warning: unused variable: `table_nodes`
   --> src/query/planner.rs:110:72
    |
110 |     fn find_join_path(&self, joins: &[crate::query::parser::JoinInfo], table_nodes: &[NodeId]) -> Result<Vec<EdgeId>> {
    |                                                                        ^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_table_nodes`

warning: variable does not need to be mutable
   --> src/query/planner.rs:111:13
    |
111 |         let mut edges = vec![];
    |             ----^^^^^
    |             |
    |             help: remove this `mut`

warning: unused variable: `having_pred`
   --> src/query/planner.rs:282:25
    |
282 |             if let Some(having_pred) = &parsed.having {
    |                         ^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_having_pred`

warning: unused variable: `target`
  --> src/query/cache.rs:79:32
   |
79 |     pub fn find_similar(&self, target: &QuerySignature) -> Option<&QueryPlan> {
   |                                ^^^^^^ help: if this is intentional, prefix it with an underscore: `_target`

warning: unused variable: `edge`
   --> src/query/optimizer.rs:111:25
    |
111 |             if let Some(edge) = self.graph.get_edge(edge_id) {
    |                         ^^^^ help: if this is intentional, prefix it with an underscore: `_edge`

warning: value assigned to `best_cost` is never read
   --> src/query/optimizer.rs:131:13
    |
131 |             best_cost = cost;
    |             ^^^^^^^^^
    |
    = help: maybe it is overwritten before being read?

warning: variable does not need to be mutable
   --> src/query/optimizer.rs:124:13
    |
124 |         let mut best_order: Vec<EdgeId> = join_graph.edges.iter().cloned().collect();
    |             ----^^^^^^^^^^
    |             |
    |             help: remove this `mut`

warning: unused variable: `edge`
   --> src/query/optimizer.rs:164:21
    |
164 |         if let Some(edge) = self.graph.get_edge(edge_id) {
    |                     ^^^^ help: if this is intentional, prefix it with an underscore: `_edge`

warning: unused variable: `current`
   --> src/query/optimizer.rs:162:28
    |
162 |     fn can_add_edge(&self, current: &[EdgeId], edge_id: EdgeId) -> Result<bool> {
    |                            ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_current`

warning: unused variable: `subquery`
   --> src/query/expression.rs:190:34
    |
190 |             Expression::Subquery(subquery) => {
    |                                  ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_subquery`

warning: unused variable: `subquery`
   --> src/query/expression.rs:196:32
    |
196 |             Expression::Exists(subquery) => {
    |                                ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_subquery`

warning: unused variable: `cte_def`
   --> src/query/cte.rs:101:13
    |
101 |         let cte_def = self.context.get(cte_name)
    |             ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_cte_def`

warning: unused variable: `args`
 --> src/query/scalar_functions.rs:7:45
  |
7 | pub fn evaluate_scalar_function(name: &str, args: &[Value]) -> Result<Value> {
  |                                             ^^^^ help: if this is intentional, prefix it with an underscore: `_args`

warning: unused variable: `with`
  --> src/query/parser_enhanced.rs:12:43
   |
12 |             let cte_context = if let Some(with) = &query.with {
   |                                           ^^^^ help: if this is intentional, prefix it with an underscore: `_with`

warning: unused variable: `op`
  --> src/query/parser_enhanced.rs:41:51
   |
41 |             } else if let SetExpr::SetOperation { op, left, right, .. } = &*query.body {
   |                                                   ^^-
   |                                                   |
   |                                                   help: try removing the field

warning: unused variable: `left`
  --> src/query/parser_enhanced.rs:41:55
   |
41 |             } else if let SetExpr::SetOperation { op, left, right, .. } = &*query.body {
   |                                                       ^^^^-
   |                                                       |
   |                                                       help: try removing the field

warning: unused variable: `right`
  --> src/query/parser_enhanced.rs:41:61
   |
41 |             } else if let SetExpr::SetOperation { op, left, right, .. } = &*query.body {
   |                                                             ^^^^^-
   |                                                             |
   |                                                             help: try removing the field

warning: unused variable: `alias`
   --> src/query/parser_enhanced.rs:112:40
    |
112 |             TableFactor::Table { name, alias, .. } => {
    |                                        ^^^^^-
    |                                        |
    |                                        help: try removing the field

warning: unused variable: `expr`
   --> src/query/parser_enhanced.rs:190:41
    |
190 |             SelectItem::ExprWithAlias { expr, alias } => {
    |                                         ^^^^ help: try ignoring the field: `expr: _`

warning: unused variable: `if_exists`
  --> src/query/ddl.rs:75:13
   |
75 |             if_exists,
   |             ^^^^^^^^^-
   |             |
   |             help: try removing the field

warning: unused variable: `current_fragment_size`
   --> src/execution/operators.rs:170:21
    |
170 |                 let current_fragment_size = self.column_fragments[0][self.current_fragment_idx].len();
    |                     ^^^^^^^^^^^^^^^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
170 |                 let _current_fragment_size = self.column_fragments[0][self.current_fragment_idx].len();
    |                     +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
170 -                 let current_fragment_size = self.column_fragments[0][self.current_fragment_idx].len();
170 +                 let execution::simd_kernels::SIMD_LANES = self.column_fragments[0][self.current_fragment_idx].len();
    |

warning: unused variable: `right_idx`
   --> src/execution/operators.rs:736:30
    |
736 |                         for &right_idx in right_indices {
    |                              ^^^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
736 |                         for &_right_idx in right_indices {
    |                              +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
736 -                         for &right_idx in right_indices {
736 +                         for &execution::simd_kernels::SIMD_LANES in right_indices {
    |

warning: unused variable: `idx`
   --> src/execution/operators.rs:806:14
    |
806 |         for (idx, field) in right_schema.fields().iter().enumerate() {
    |              ^^^
    |
help: if this is intentional, prefix it with an underscore
    |
806 |         for (_idx, field) in right_schema.fields().iter().enumerate() {
    |              +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
806 -         for (idx, field) in right_schema.fields().iter().enumerate() {
806 +         for (execution::simd_kernels::SIMD_LANES, field) in right_schema.fields().iter().enumerate() {
    |

warning: unused variable: `idx`
   --> src/execution/operators.rs:853:14
    |
853 |         for (idx, field) in right_schema.fields().iter().enumerate() {
    |              ^^^
    |
help: if this is intentional, prefix it with an underscore
    |
853 |         for (_idx, field) in right_schema.fields().iter().enumerate() {
    |              +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
853 -         for (idx, field) in right_schema.fields().iter().enumerate() {
853 +         for (execution::simd_kernels::SIMD_LANES, field) in right_schema.fields().iter().enumerate() {
    |

warning: variable does not need to be mutable
    --> src/execution/operators.rs:1363:25
     |
1363 |                     let mut col_values: Vec<Value> = sorted_rows.iter().map(|row| row[col_idx].clone()).collect();
     |                         ----^^^^^^^^^^
     |                         |
     |                         help: remove this `mut`

warning: unused variable: `array`
  --> src/execution/wcoj.rs:91:22
   |
91 |     fn extract_value(array: &dyn Array, idx: usize) -> Value {
   |                      ^^^^^ help: if this is intentional, prefix it with an underscore: `_array`

warning: unused variable: `idx`
  --> src/execution/wcoj.rs:91:41
   |
91 |     fn extract_value(array: &dyn Array, idx: usize) -> Value {
   |                                         ^^^
   |
help: if this is intentional, prefix it with an underscore
   |
91 |     fn extract_value(array: &dyn Array, _idx: usize) -> Value {
   |                                         +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
   |
91 -     fn extract_value(array: &dyn Array, idx: usize) -> Value {
91 +     fn extract_value(array: &dyn Array, execution::simd_kernels::SIMD_LANES: usize) -> Value {
   |

warning: unused variable: `var_idx`
   --> src/execution/wcoj.rs:244:52
    |
244 |     fn get_values_for_variable(&self, trie: &Trie, var_idx: usize) -> Result<Vec<Value>> {
    |                                                    ^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
244 |     fn get_values_for_variable(&self, trie: &Trie, _var_idx: usize) -> Result<Vec<Value>> {
    |                                                    +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
244 -     fn get_values_for_variable(&self, trie: &Trie, var_idx: usize) -> Result<Vec<Value>> {
244 +     fn get_values_for_variable(&self, trie: &Trie, execution::simd_kernels::SIMD_LANES: usize) -> Result<Vec<Value>> {
    |

warning: unused variable: `var_idx`
   --> src/execution/wcoj.rs:276:36
    |
276 |     fn advance_variable(&mut self, var_idx: usize) -> Result<bool> {
    |                                    ^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
276 |     fn advance_variable(&mut self, _var_idx: usize) -> Result<bool> {
    |                                    +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
276 -     fn advance_variable(&mut self, var_idx: usize) -> Result<bool> {
276 +     fn advance_variable(&mut self, execution::simd_kernels::SIMD_LANES: usize) -> Result<bool> {
    |

warning: unused variable: `tuple`
   --> src/execution/wcoj.rs:299:21
    |
299 |         if let Some(tuple) = self.advance()? {
    |                     ^^^^^ help: if this is intentional, prefix it with an underscore: `_tuple`

warning: unused variable: `join_graph`
   --> src/execution/wcoj.rs:318:5
    |
318 |     join_graph: &HyperGraph,
    |     ^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_join_graph`

warning: unused variable: `i`
   --> src/execution/simd_kernels.rs:267:17
    |
267 |             for i in 0..array.len() {
    |                 ^
    |
help: if this is intentional, prefix it with an underscore
    |
267 |             for _i in 0..array.len() {
    |                 +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
267 -             for i in 0..array.len() {
267 +             for execution::simd_kernels::SIMD_LANES in 0..array.len() {
    |

warning: variable does not need to be mutable
   --> src/execution/simd_kernels.rs:266:17
    |
266 |             let mut result = vec![false; array.len()];
    |                 ----^^^^^^
    |                 |
    |                 help: remove this `mut`

warning: unused variable: `table`
  --> src/incremental/propagator.rs:32:32
   |
32 |     fn propagate_insert(&self, table: &str, _delta: &DeltaOperation) -> Result<()> {
   |                                ^^^^^ help: if this is intentional, prefix it with an underscore: `_table`

warning: unused variable: `table`
  --> src/incremental/propagator.rs:42:32
   |
42 |     fn propagate_update(&self, table: &str, _delta: &DeltaOperation) -> Result<()> {
   |                                ^^^^^ help: if this is intentional, prefix it with an underscore: `_table`

warning: unused variable: `table`
  --> src/incremental/propagator.rs:47:32
   |
47 |     fn propagate_delete(&self, table: &str, _delta: &DeltaOperation) -> Result<()> {
   |                                ^^^^^ help: if this is intentional, prefix it with an underscore: `_table`

warning: unused variable: `table`
  --> src/cache/result_cache.rs:64:40
   |
64 |     pub fn invalidate_table(&mut self, table: &str) {
   |                                        ^^^^^ help: if this is intentional, prefix it with an underscore: `_table`

warning: unused variable: `plan`
  --> src/distributed/coordinator.rs:15:39
   |
15 |     pub fn execute_distributed(&self, plan: &QueryPlan) -> Result<()> {
   |                                       ^^^^ help: if this is intentional, prefix it with an underscore: `_plan`

warning: unused variable: `optimal_order`
   --> src/engine.rs:190:23
    |
190 |             if let Ok(optimal_order) = self.optimizer.optimize_joins(&path) {
    |                       ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_optimal_order`

warning: variable does not need to be mutable
   --> src/engine.rs:186:13
    |
186 |         let mut plan = planner.plan(&parsed)?;
    |             ----^^^^
    |             |
    |             help: remove this `mut`

warning: unused variable: `fragment_idx`
   --> src/engine.rs:387:22
    |
387 |                 for (fragment_idx, fragment) in node.fragments.iter().enumerate() {
    |                      ^^^^^^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
387 |                 for (_fragment_idx, fragment) in node.fragments.iter().enumerate() {
    |                      +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
387 -                 for (fragment_idx, fragment) in node.fragments.iter().enumerate() {
387 +                 for (execution::simd_kernels::SIMD_LANES, fragment) in node.fragments.iter().enumerate() {
    |

warning: unused variable: `optimal_size`
   --> src/engine.rs:397:29
    |
397 |                         let optimal_size = self.adaptive_fragment_manager.optimal_fragment_size(&pattern);
    |                             ^^^^^^^^^^^^
    |
help: if this is intentional, prefix it with an underscore
    |
397 |                         let _optimal_size = self.adaptive_fragment_manager.optimal_fragment_size(&pattern);
    |                             +
help: you might have meant to pattern match on the similarly named constant `SIMD_LANES`
    |
397 -                         let optimal_size = self.adaptive_fragment_manager.optimal_fragment_size(&pattern);
397 +                         let execution::simd_kernels::SIMD_LANES = self.adaptive_fragment_manager.optimal_fragment_size(&pattern);
    |

warning: unused variable: `table_node_id`
   --> src/engine.rs:532:14
    |
532 |         let (table_node_id, _) = table_node;
    |              ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_table_node_id`

warning: unused variable: `table_node_id`
   --> src/engine.rs:558:14
    |
558 |         let (table_node_id, _) = table_node;
    |              ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_table_node_id`

warning: unused variable: `node_id`
   --> src/engine.rs:633:13
    |
633 |         for node_id in nodes_to_remove {
    |             ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_node_id`

warning: type `CompressedNode` is more private than the item `HypergraphCompressor::compress_node`
  --> src/hypergraph/compression.rs:47:5
   |
47 |     pub fn compress_node(&self, node: &HyperNode) -> Result<CompressedNode, Box<dyn std::error::Error>> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::compress_node` is reachable at visibility `pub`
   |
note: but type `CompressedNode` is only usable at visibility `pub(self)`
  --> src/hypergraph/compression.rs:21:1
   |
21 | struct CompressedNode {
   | ^^^^^^^^^^^^^^^^^^^^^
   = note: `#[warn(private_interfaces)]` on by default

warning: type `CompressedEdge` is more private than the item `HypergraphCompressor::compress_edge`
  --> src/hypergraph/compression.rs:73:5
   |
73 |     pub fn compress_edge(&self, edge: &HyperEdge) -> Result<CompressedEdge, Box<dyn std::error::Error>> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::compress_edge` is reachable at visibility `pub`
   |
note: but type `CompressedEdge` is only usable at visibility `pub(self)`
  --> src/hypergraph/compression.rs:27:1
   |
27 | struct CompressedEdge {
   | ^^^^^^^^^^^^^^^^^^^^^

warning: type `CompressedNode` is more private than the item `HypergraphCompressor::decompress_node`
  --> src/hypergraph/compression.rs:97:5
   |
97 |     pub fn decompress_node(&self, compressed: &CompressedNode) -> Result<NodeMetadata, Box<dyn std::error::Error>> {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::decompress_node` is reachable at visibility `pub`
   |
note: but type `CompressedNode` is only usable at visibility `pub(self)`
  --> src/hypergraph/compression.rs:21:1
   |
21 | struct CompressedNode {
   | ^^^^^^^^^^^^^^^^^^^^^

warning: type `NodeMetadata` is more private than the item `HypergraphCompressor::decompress_node`
   --> src/hypergraph/compression.rs:97:5
    |
 97 |     pub fn decompress_node(&self, compressed: &CompressedNode) -> Result<NodeMetadata, Box<dyn std::error::Error>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::decompress_node` is reachable at visibility `pub`
    |
note: but type `NodeMetadata` is only usable at visibility `pub(self)`
   --> src/hypergraph/compression.rs:112:1
    |
112 | struct NodeMetadata {
    | ^^^^^^^^^^^^^^^^^^^

warning: type `CompressedEdge` is more private than the item `HypergraphCompressor::decompress_edge`
   --> src/hypergraph/compression.rs:104:5
    |
104 |     pub fn decompress_edge(&self, compressed: &CompressedEdge) -> Result<EdgeMetadata, Box<dyn std::error::Error>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::decompress_edge` is reachable at visibility `pub`
    |
note: but type `CompressedEdge` is only usable at visibility `pub(self)`
   --> src/hypergraph/compression.rs:27:1
    |
 27 | struct CompressedEdge {
    | ^^^^^^^^^^^^^^^^^^^^^

warning: type `EdgeMetadata` is more private than the item `HypergraphCompressor::decompress_edge`
   --> src/hypergraph/compression.rs:104:5
    |
104 |     pub fn decompress_edge(&self, compressed: &CompressedEdge) -> Result<EdgeMetadata, Box<dyn std::error::Error>> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `HypergraphCompressor::decompress_edge` is reachable at visibility `pub`
    |
note: but type `EdgeMetadata` is only usable at visibility `pub(self)`
   --> src/hypergraph/compression.rs:123:1
    |
123 | struct EdgeMetadata {
    | ^^^^^^^^^^^^^^^^^^^

warning: type `CoarsenedNode` is more private than the item `CoarsenedHyperGraph::get_coarsened_node`
   --> src/hypergraph/coarsening.rs:332:5
    |
332 |     pub fn get_coarsened_node(&self, original_id: NodeId) -> Option<&CoarsenedNode> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `CoarsenedHyperGraph::get_coarsened_node` is reachable at visibility `pub`
    |
note: but type `CoarsenedNode` is only usable at visibility `pub(self)`
   --> src/hypergraph/coarsening.rs:28:1
    |
 28 | struct CoarsenedNode {
    | ^^^^^^^^^^^^^^^^^^^^

warning: type `CoarsenedEdge` is more private than the item `CoarsenedHyperGraph::get_coarsened_edge`
   --> src/hypergraph/coarsening.rs:338:5
    |
338 |     pub fn get_coarsened_edge(&self, original_id: EdgeId) -> Option<&CoarsenedEdge> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `CoarsenedHyperGraph::get_coarsened_edge` is reachable at visibility `pub`
    |
note: but type `CoarsenedEdge` is only usable at visibility `pub(self)`
   --> src/hypergraph/coarsening.rs:40:1
    |
 40 | struct CoarsenedEdge {
    | ^^^^^^^^^^^^^^^^^^^^

warning: type `TrieNode` is more private than the item `Trie::get_child`
   --> src/execution/wcoj.rs:102:5
    |
102 |     pub fn get_child(&self, value: &Value) -> Option<&TrieNode> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ method `Trie::get_child` is reachable at visibility `pub`
    |
note: but type `TrieNode` is only usable at visibility `pub(self)`
   --> src/execution/wcoj.rs:25:1
    |
 25 | enum TrieNode {
    | ^^^^^^^^^^^^^

warning: field `capacity` is never read
  --> src/storage/index.rs:34:5
   |
32 | pub struct BloomIndex {
   |            ---------- field in this struct
33 |     bits: Vec<u8>,
34 |     capacity: usize,
   |     ^^^^^^^^
   |
   = note: `BloomIndex` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis
   = note: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default

warning: field `is_leaf` is never read
   --> src/storage/index.rs:316:5
    |
313 | struct BTreeNode {
    |        --------- field in this struct
...
316 |     is_leaf: bool,
    |     ^^^^^^^
    |
    = note: `BTreeNode` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis

warning: fields `min_value` and `max_value` are never read
  --> src/storage/learned_index.rs:46:5
   |
38 | pub struct LinearModel {
   |            ----------- fields in this struct
...
46 |     min_value: f64,
   |     ^^^^^^^^^
...
49 |     max_value: f64,
   |     ^^^^^^^^^
   |
   = note: `LinearModel` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis

warning: field `alignment` is never read
  --> src/storage/cache_layout.rs:99:5
   |
94 | pub struct CacheOptimizedFragmentBuilder {
   |            ----------------------------- field in this struct
...
99 |     alignment: usize,
   |     ^^^^^^^^^

warning: field `data_type` is never read
  --> src/storage/tiered_index.rs:31:5
   |
14 | pub struct TieredIndex {
   |            ----------- field in this struct
...
31 |     data_type: DataType,
   |     ^^^^^^^^^
   |
   = note: `TieredIndex` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis

warning: fields `fragment_id` and `memory_tier` are never read
   --> src/storage/tiered_index.rs:297:5
    |
292 | pub struct MemoryFilter {
    |            ------------ fields in this struct
...
297 |     fragment_id: (NodeId, usize),
    |     ^^^^^^^^^^^
...
300 |     memory_tier: crate::storage::memory_tier::MemoryTier,
    |     ^^^^^^^^^^^

warning: field `filters` is never read
   --> src/storage/tiered_index.rs:408:5
    |
403 | pub struct TieredIndexManager {
    |            ------------------ field in this struct
...
408 |     filters: dashmap::DashMap<(NodeId, usize), MemoryFilter>,
    |     ^^^^^^^

warning: fields `compressed_nodes`, `compressed_edges`, and `compression_ratio` are never read
  --> src/hypergraph/compression.rs:12:5
   |
10 | pub struct CompressedHyperGraph {
   |            -------------------- fields in this struct
11 |     /// Compressed node data
12 |     compressed_nodes: Vec<CompressedNode>,
   |     ^^^^^^^^^^^^^^^^
...
15 |     compressed_edges: Vec<CompressedEdge>,
   |     ^^^^^^^^^^^^^^^^
...
18 |     compression_ratio: f64,
   |     ^^^^^^^^^^^^^^^^^

warning: fields `id` and `original_size` are never read
  --> src/hypergraph/compression.rs:22:5
   |
21 | struct CompressedNode {
   |        -------------- fields in this struct
22 |     id: NodeId,
   |     ^^
23 |     compressed_data: Vec<u8>,
24 |     original_size: usize,
   |     ^^^^^^^^^^^^^

warning: fields `id` and `original_size` are never read
  --> src/hypergraph/compression.rs:28:5
   |
27 | struct CompressedEdge {
   |        -------------- fields in this struct
28 |     id: EdgeId,
   |     ^^
29 |     compressed_data: Vec<u8>,
30 |     original_size: usize,
   |     ^^^^^^^^^^^^^

warning: fields `node_id`, `operation`, and `data` are never read
   --> src/hypergraph/compression.rs:259:5
    |
258 | pub struct DeltaEntry {
    |            ---------- fields in this struct
259 |     node_id: NodeId,
    |     ^^^^^^^
260 |     operation: DeltaOperation,
    |     ^^^^^^^^^
261 |     data: Vec<u8>,
    |     ^^^^
    |
    = note: `DeltaEntry` has derived impls for the traits `Debug` and `Clone`, but these are intentionally ignored during dead code analysis

warning: fields `original_nodes`, `representative`, and `aggregated_stats` are never read
  --> src/hypergraph/coarsening.rs:30:5
   |
28 | struct CoarsenedNode {
   |        ------------- fields in this struct
29 |     /// Original node IDs that were merged
30 |     original_nodes: Vec<NodeId>,
   |     ^^^^^^^^^^^^^^
...
33 |     representative: NodeId,
   |     ^^^^^^^^^^^^^^
...
36 |     aggregated_stats: NodeStatistics,
   |     ^^^^^^^^^^^^^^^^

warning: fields `original_edges`, `representative`, and `aggregated_stats` are never read
  --> src/hypergraph/coarsening.rs:42:5
   |
40 | struct CoarsenedEdge {
   |        ------------- fields in this struct
41 |     /// Original edge IDs that were merged
42 |     original_edges: Vec<EdgeId>,
   |     ^^^^^^^^^^^^^^
...
45 |     representative: EdgeId,
   |     ^^^^^^^^^^^^^^
...
48 |     aggregated_stats: EdgeStatistics,
   |     ^^^^^^^^^^^^^^^^

warning: fields `total_rows`, `total_fragments`, and `avg_cardinality` are never read
  --> src/hypergraph/coarsening.rs:54:5
   |
53 | struct NodeStatistics {
   |        -------------- fields in this struct
54 |     total_rows: usize,
   |     ^^^^^^^^^^
55 |     total_fragments: usize,
   |     ^^^^^^^^^^^^^^^
56 |     avg_cardinality: f64,
   |     ^^^^^^^^^^^^^^^
   |
   = note: `NodeStatistics` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis

warning: fields `total_joins` and `avg_selectivity` are never read
  --> src/hypergraph/coarsening.rs:62:5
   |
61 | struct EdgeStatistics {
   |        -------------- fields in this struct
62 |     total_joins: usize,
   |     ^^^^^^^^^^^
63 |     avg_selectivity: f64,
   |     ^^^^^^^^^^^^^^^
   |
   = note: `EdgeStatistics` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis

warning: field `coarsening_level` is never read
  --> src/hypergraph/coarsening.rs:69:5
   |
67 | pub struct HypergraphCoarsener {
   |            ------------------- field in this struct
68 |     /// Coarsening level (higher = more aggressive merging)
69 |     coarsening_level: f64,
   |     ^^^^^^^^^^^^^^^^

warning: methods `enumerate_orders` and `can_add_edge` are never used
   --> src/query/optimizer.rs:138:8
    |
 81 | impl HypergraphOptimizer {
    | ------------------------ methods in this implementation
...
138 |     fn enumerate_orders<F>(&self, remaining: &[EdgeId], current: &mut Vec<EdgeId>, f: &mut F) -> Result<()>
    |        ^^^^^^^^^^^^^^^^
...
162 |     fn can_add_edge(&self, current: &[EdgeId], edge_id: EdgeId) -> Result<bool> {
    |        ^^^^^^^^^^^^

warning: field `nodes` is never read
   --> src/query/optimizer.rs:192:5
    |
191 | struct JoinGraph {
    |        --------- field in this struct
192 |     nodes: HashSet<NodeId>,
    |     ^^^^^

warning: field `graph` is never read
  --> src/query/cte.rs:91:5
   |
87 | pub struct CTEResolver {
   |            ----------- field in this struct
...
91 |     graph: Arc<HyperGraph>,
   |     ^^^^^

warning: field `batch_size` is never read
  --> src/execution/engine.rs:13:5
   |
10 | pub struct ExecutionEngine {
   |            --------------- field in this struct
...
13 |     batch_size: usize,
   |     ^^^^^^^^^^

warning: field `table` is never read
  --> src/execution/operators.rs:20:5
   |
18 | pub struct ScanOperator {
   |            ------------ field in this struct
19 |     node_id: NodeId,
20 |     table: String,
   |     ^^^^^

warning: fields `graph` and `edge_id` are never read
   --> src/execution/operators.rs:626:5
    |
621 | pub struct JoinOperator {
    |            ------------ fields in this struct
...
626 |     graph: std::sync::Arc<HyperGraph>,
    |     ^^^^^
627 |     edge_id: EdgeId,
    |     ^^^^^^^

warning: field `iterators` is never read
   --> src/execution/wcoj.rs:130:5
    |
126 | struct WCOJState {
    |        --------- field in this struct
...
130 |     iterators: Vec<usize>,
    |     ^^^^^^^^^

warning: field `reoptimize_threshold` is never read
  --> src/execution/adaptive.rs:50:5
   |
48 | pub struct AdaptiveExecutionEngine {
   |            ----------------------- field in this struct
49 |     base_engine: std::sync::Arc<ExecutionEngine>,
50 |     reoptimize_threshold: f64,
   |     ^^^^^^^^^^^^^^^^^^^^

warning: field `graph` is never read
 --> src/incremental/propagator.rs:8:5
  |
7 | pub struct IncrementalPropagator {
  |            --------------------- field in this struct
8 |     graph: HyperGraph,
  |     ^^^^^

warning: field `nodes` is never read
 --> src/distributed/coordinator.rs:6:5
  |
5 | pub struct DistributedCoordinator {
  |            ---------------------- field in this struct
6 |     nodes: Vec<String>, // Node addresses
  |     ^^^^^

warning: fields `local_cost` and `network_cost_per_byte` are never read
  --> src/distributed/sharding.rs:12:5
   |
10 | pub struct ShardingCostModel {
   |            ----------------- fields in this struct
11 |     /// Cost per local access
12 |     local_cost: f64,
   |     ^^^^^^^^^^
...
16 |     network_cost_per_byte: f64,
   |     ^^^^^^^^^^^^^^^^^^^^^

warning: `hypergraph-sql-engine` (lib) generated 144 warnings (run `cargo fix --lib -p hypergraph-sql-engine` to apply 63 suggestions)
warning: unused variable: `idx`
   --> src/bin/compare_engines.rs:769:10
    |
769 |     for (idx, row) in rows.iter().take(max_rows).enumerate() {
    |          ^^^
    |
    = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default
help: if this is intentional, prefix it with an underscore
    |
769 |     for (_idx, row) in rows.iter().take(max_rows).enumerate() {
    |          +
help: you might have meant to pattern match on the similarly named constant `BENCHMARK_RUNS`
    |
769 -     for (idx, row) in rows.iter().take(max_rows).enumerate() {
769 +     for (main::{closure#0}::BENCHMARK_RUNS, row) in rows.iter().take(max_rows).enumerate() {
    |

warning: `hypergraph-sql-engine` (bin "compare_engines") generated 1 warning (run `cargo fix --bin "compare_engines"` to apply 1 suggestion)
    Finished `release` profile [optimized] target(s) in 0.08s
     Running `target/release/compare_engines /Users/niyathnair/Downloads/LQS/annual-enterprise-survey-2024-financial-year-provisional.csv`
ğŸš€ Hypergraph SQL Engine vs PostgreSQL Benchmark
================================================================================
Loading data from: /Users/niyathnair/Downloads/LQS/annual-enterprise-survey-2024-financial-year-provisional.csv
âœ“ Loaded 55620 rows, 10 columns in 40.637792ms
âœ“ Loaded table 'enterprise_survey' into hypergraph (node_id: NodeId(1)) with 10 columns
âœ“ Table loaded into hypergraph in 68.85175ms

ğŸ“Š Connecting to PostgreSQL...
âœ“ Connected to PostgreSQL
ğŸ“Š Loading data into PostgreSQL...
âœ“ Data loaded into PostgreSQL in 7.1356835s

ğŸ“Š Connecting to DuckDB...
âœ“ Connected to DuckDB
ğŸ“Š Loading data into DuckDB...
âœ“ Data loaded into DuckDB in 8.571174166s

================================================================================
ğŸ“Š Running Fair Benchmark Comparison
================================================================================
Each query runs 5 times (with 2 warmup runs) and we report the average
Result cache is disabled for Hypergraph during benchmarking
Comparing: Hypergraph SQL Engine vs PostgreSQL vs DuckDB
================================================================================

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query 1: SELECT * FROM enterprise_survey LIMIT 10
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”· Hypergraph Engine:
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 32.25Âµs
   Execute: 49.125Âµs
   Collect: 1.333Âµs
   Total: 82.833Âµs (0.08ms)
   Rows: 10
   Throughput: 120724.83 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 7Âµs
   Execute: 24.875Âµs
   Collect: 1.833Âµs
   Total: 33.791Âµs (0.03ms)
   Rows: 10
   Throughput: 295936.79 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.625Âµs
   Execute: 24.125Âµs
   Collect: 1.625Âµs
   Total: 31.459Âµs (0.03ms)
   Rows: 10
   Throughput: 317874.06 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 8.167Âµs
   Execute: 24Âµs
   Collect: 4.167Âµs
   Total: 36.417Âµs (0.04ms)
   Rows: 10
   Throughput: 274597.03 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 7.625Âµs
   Execute: 30.709Âµs
   Collect: 1.375Âµs
   Total: 39.875Âµs (0.04ms)
   Rows: 10
   Throughput: 250783.70 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.583Âµs
   Execute: 25.833Âµs
   Collect: 1.75Âµs
   Total: 34.208Âµs (0.03ms)
   Rows: 10
   Throughput: 292329.28 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.417Âµs
   Execute: 18.375Âµs
   Collect: 1.625Âµs
   Total: 26.458Âµs (0.03ms)
   Rows: 10
   Throughput: 377957.52 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.417Âµs
   Execute: 18.25Âµs
   Collect: 1.416Âµs
   Total: 25.125Âµs (0.03ms)
   Rows: 10
   Throughput: 398009.95 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.917Âµs
   Execute: 30.458Âµs
   Collect: 1.666Âµs
   Total: 38.167Âµs (0.04ms)
   Rows: 10
   Throughput: 262006.45 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 7.709Âµs
   Execute: 29.584Âµs
   Collect: 1.708Âµs
   Total: 39.083Âµs (0.04ms)
   Rows: 10
   Throughput: 255865.72 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 7.042Âµs
   Execute: 23.209Âµs
   Collect: 1.667Âµs
   Total: 32Âµs (0.03ms)
   Rows: 10
   Throughput: 312500.00 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.5Âµs
   Execute: 26.125Âµs
   Collect: 1.541Âµs
   Total: 34.25Âµs (0.03ms)
   Rows: 10
   Throughput: 291970.80 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.875Âµs
   Execute: 30Âµs
   Collect: 1.5Âµs
   Total: 38.458Âµs (0.04ms)
   Rows: 10
   Throughput: 260023.92 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 7.791Âµs
   Execute: 19.75Âµs
   Collect: 1.292Âµs
   Total: 28.875Âµs (0.03ms)
   Rows: 10
   Throughput: 346320.35 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.167Âµs
   Execute: 24.125Âµs
   Collect: 1.625Âµs
   Total: 31.958Âµs (0.03ms)
   Rows: 10
   Throughput: 312910.70 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.209Âµs
   Execute: 18.125Âµs
   Collect: 1.542Âµs
   Total: 25.917Âµs (0.03ms)
   Rows: 10
   Throughput: 385847.13 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.25Âµs
   Execute: 19.417Âµs
   Collect: 1.375Âµs
   Total: 26.125Âµs (0.03ms)
   Rows: 10
   Throughput: 382775.12 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 4.958Âµs
   Execute: 40.125Âµs
   Collect: 1.25Âµs
   Total: 46.375Âµs (0.05ms)
   Rows: 10
   Throughput: 215633.42 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.833Âµs
   Execute: 30.084Âµs
   Collect: 1.334Âµs
   Total: 38.333Âµs (0.04ms)
   Rows: 10
   Throughput: 260871.83 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.792Âµs
   Execute: 22.833Âµs
   Collect: 1.75Âµs
   Total: 31.5Âµs (0.03ms)
   Rows: 10
   Throughput: 317460.32 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 9.541Âµs
   Execute: 24.875Âµs
   Collect: 1.959Âµs
   Total: 36.458Âµs (0.04ms)
   Rows: 10
   Throughput: 274288.22 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 6.292Âµs
   Execute: 19.625Âµs
   Collect: 1.5Âµs
   Total: 27.5Âµs (0.03ms)
   Rows: 10
   Throughput: 363636.36 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.375Âµs
   Execute: 18.167Âµs
   Collect: 2.625Âµs
   Total: 26.25Âµs (0.03ms)
   Rows: 10
   Throughput: 380952.38 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=10, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 10 rows (from fragment slice [0, 10))
ProjectOperator::next: Got batch with 10 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 10 rows from input
LimitOperator::next: Remaining rows to return: 10
LimitOperator::next: Returning batch with 10 rows (total returned: 10)
ExecutionEngine: Got batch with 10 rows (total so far: 10)
LimitOperator::next: rows_returned=10, limit=10, offset=0
LimitOperator::next: Already returned 10 rows, limit is 10, returning None
ExecutionEngine: Total row_count from batches: 10 (calculated: 10)
â±ï¸  Execution timing:
   Build: 5.375Âµs
   Execute: 17.959Âµs
   Collect: 1.5Âµs
   Total: 24.875Âµs (0.02ms)
   Rows: 10
   Throughput: 402010.05 rows/sec
  Run 1: 0.02513ms ... (avg of 5 runs: 0.02833ms)
  âœ“ Average: 0.02833ms | Rows: 10

  ğŸ“‹ Hypergraph Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Year |Industry_... |Industry_... |Industry_... |       Units |Variable_... |Variable_... |Variable_... |       Value |Industry_...
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H01 |Total income |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |        2863 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H05 |Interest,... |Financial... |           6 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |           0 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H08 |Total exp... |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H09 |Interest ... |Financial... |        3327 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |          42 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H11 |Depreciation |Financial... |           9 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |         169 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         485 |ANZSIC06 ...
  ... (showing first 10 rows)


ğŸ”· PostgreSQL:
  Run 1: 0.31471ms ... (avg of 5 runs: 0.29587ms)
  âœ“ Average: 0.29587ms | Rows: 10

  ğŸ“‹ PostgreSQL Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...


ğŸ”· DuckDB:
  Run 1: 0.17538ms ... (avg of 5 runs: 0.17596ms)
  âœ“ Average: 0.17596ms | Rows: 10

  ğŸ“‹ DuckDB Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...


ğŸ“Š Comparison:
  ğŸš€ Hypergraph Engine is 10.44233x FASTER than PostgreSQL
  ğŸš€ Hypergraph Engine is 6.21027x FASTER than DuckDB

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query 2: SELECT * FROM enterprise_survey LIMIT 100
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”· Hypergraph Engine:
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.083Âµs
   Execute: 27.167Âµs
   Collect: 1.416Âµs
   Total: 34.75Âµs (0.03ms)
   Rows: 100
   Throughput: 2877697.84 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.958Âµs
   Execute: 34.167Âµs
   Collect: 1.625Âµs
   Total: 42.833Âµs (0.04ms)
   Rows: 100
   Throughput: 2334648.52 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.667Âµs
   Execute: 25.916Âµs
   Collect: 1.875Âµs
   Total: 34.5Âµs (0.03ms)
   Rows: 100
   Throughput: 2898550.72 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.375Âµs
   Execute: 22.208Âµs
   Collect: 1.417Âµs
   Total: 30.084Âµs (0.03ms)
   Rows: 100
   Throughput: 3324026.06 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.584Âµs
   Execute: 23.959Âµs
   Collect: 1.916Âµs
   Total: 32.5Âµs (0.03ms)
   Rows: 100
   Throughput: 3076923.08 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.667Âµs
   Execute: 22.291Âµs
   Collect: 1.583Âµs
   Total: 29.625Âµs (0.03ms)
   Rows: 100
   Throughput: 3375527.43 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.916Âµs
   Execute: 18.458Âµs
   Collect: 3.25Âµs
   Total: 27.75Âµs (0.03ms)
   Rows: 100
   Throughput: 3603603.60 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 4.75Âµs
   Execute: 20.584Âµs
   Collect: 1.458Âµs
   Total: 26.833Âµs (0.03ms)
   Rows: 100
   Throughput: 3726754.37 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.167Âµs
   Execute: 28.458Âµs
   Collect: 1.833Âµs
   Total: 36.583Âµs (0.04ms)
   Rows: 100
   Throughput: 2733510.10 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.708Âµs
   Execute: 26.333Âµs
   Collect: 1.584Âµs
   Total: 33.708Âµs (0.03ms)
   Rows: 100
   Throughput: 2966654.80 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.541Âµs
   Execute: 18.667Âµs
   Collect: 1.333Âµs
   Total: 25.667Âµs (0.03ms)
   Rows: 100
   Throughput: 3896053.30 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 4.583Âµs
   Execute: 22.875Âµs
   Collect: 1.417Âµs
   Total: 29Âµs (0.03ms)
   Rows: 100
   Throughput: 3448275.86 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.417Âµs
   Execute: 17.75Âµs
   Collect: 1.458Âµs
   Total: 24.708Âµs (0.02ms)
   Rows: 100
   Throughput: 4047272.14 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.625Âµs
   Execute: 24.334Âµs
   Collect: 1.834Âµs
   Total: 31.875Âµs (0.03ms)
   Rows: 100
   Throughput: 3137254.90 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.791Âµs
   Execute: 29.917Âµs
   Collect: 1.25Âµs
   Total: 37.083Âµs (0.04ms)
   Rows: 100
   Throughput: 2696653.45 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.541Âµs
   Execute: 22.833Âµs
   Collect: 1.708Âµs
   Total: 31.25Âµs (0.03ms)
   Rows: 100
   Throughput: 3200000.00 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.625Âµs
   Execute: 22.458Âµs
   Collect: 4.5Âµs
   Total: 32.667Âµs (0.03ms)
   Rows: 100
   Throughput: 3061193.25 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.25Âµs
   Execute: 19.709Âµs
   Collect: 1.333Âµs
   Total: 27.333Âµs (0.03ms)
   Rows: 100
   Throughput: 3658581.20 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.166Âµs
   Execute: 23.542Âµs
   Collect: 1.875Âµs
   Total: 30.75Âµs (0.03ms)
   Rows: 100
   Throughput: 3252032.52 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.625Âµs
   Execute: 24.084Âµs
   Collect: 1.416Âµs
   Total: 32.166Âµs (0.03ms)
   Rows: 100
   Throughput: 3108872.72 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 11.916Âµs
   Execute: 25.667Âµs
   Collect: 1.667Âµs
   Total: 39.375Âµs (0.04ms)
   Rows: 100
   Throughput: 2539682.54 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.167Âµs
   Execute: 29.25Âµs
   Collect: 1.667Âµs
   Total: 37.208Âµs (0.04ms)
   Rows: 100
   Throughput: 2687594.07 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.959Âµs
   Execute: 22.166Âµs
   Collect: 1.375Âµs
   Total: 29.542Âµs (0.03ms)
   Rows: 100
   Throughput: 3385011.17 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.667Âµs
   Execute: 27.292Âµs
   Collect: 1.875Âµs
   Total: 34.917Âµs (0.03ms)
   Rows: 100
   Throughput: 2863934.47 rows/sec
  Run 1: 0.02683ms ... (avg of 5 runs: 0.03083ms)
  âœ“ Average: 0.03083ms | Rows: 100

  ğŸ“‹ Hypergraph Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Year |Industry_... |Industry_... |Industry_... |       Units |Variable_... |Variable_... |Variable_... |       Value |Industry_...
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H01 |Total income |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |        2863 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H05 |Interest,... |Financial... |           6 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |           0 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H08 |Total exp... |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H09 |Interest ... |Financial... |        3327 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |          42 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H11 |Depreciation |Financial... |           9 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |         169 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         485 |ANZSIC06 ...
  ... (showing first 10 rows)


ğŸ”· PostgreSQL:
  Run 1: 0.31029ms ... (avg of 5 runs: 0.33460ms)
  âœ“ Average: 0.33460ms | Rows: 100

  ğŸ“‹ PostgreSQL Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...
  ... (showing first 10 of 100 rows)


ğŸ”· DuckDB:
  Run 1: 0.40179ms ... (avg of 5 runs: 0.38291ms)
  âœ“ Average: 0.38291ms | Rows: 100

  ğŸ“‹ DuckDB Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...
  ... (showing first 10 of 100 rows)


ğŸ“Š Comparison:
  ğŸš€ Hypergraph Engine is 10.85193x FASTER than PostgreSQL
  ğŸš€ Hypergraph Engine is 12.41870x FASTER than DuckDB

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query 3: SELECT * FROM enterprise_survey LIMIT 1000
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”· Hypergraph Engine:
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 8.708Âµs
   Execute: 27.25Âµs
   Collect: 1.542Âµs
   Total: 37.542Âµs (0.04ms)
   Rows: 1000
   Throughput: 26636833.41 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 8.708Âµs
   Execute: 19.584Âµs
   Collect: 2.791Âµs
   Total: 31.083Âµs (0.03ms)
   Rows: 1000
   Throughput: 32171926.78 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.959Âµs
   Execute: 23.709Âµs
   Collect: 1.75Âµs
   Total: 31.5Âµs (0.03ms)
   Rows: 1000
   Throughput: 31746031.75 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.541Âµs
   Execute: 26.417Âµs
   Collect: 1.833Âµs
   Total: 34.833Âµs (0.03ms)
   Rows: 1000
   Throughput: 28708408.69 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.542Âµs
   Execute: 26.417Âµs
   Collect: 1.791Âµs
   Total: 34.792Âµs (0.03ms)
   Rows: 1000
   Throughput: 28742239.60 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.584Âµs
   Execute: 18.125Âµs
   Collect: 1.334Âµs
   Total: 25.125Âµs (0.03ms)
   Rows: 1000
   Throughput: 39800995.02 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.459Âµs
   Execute: 22.375Âµs
   Collect: 1.458Âµs
   Total: 29.334Âµs (0.03ms)
   Rows: 1000
   Throughput: 34090134.32 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.042Âµs
   Execute: 19.333Âµs
   Collect: 1.333Âµs
   Total: 26.791Âµs (0.03ms)
   Rows: 1000
   Throughput: 37325967.68 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.5Âµs
   Execute: 22.208Âµs
   Collect: 3.958Âµs
   Total: 31.792Âµs (0.03ms)
   Rows: 1000
   Throughput: 31454453.95 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.875Âµs
   Execute: 18.209Âµs
   Collect: 1.291Âµs
   Total: 25.5Âµs (0.03ms)
   Rows: 1000
   Throughput: 39215686.27 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.25Âµs
   Execute: 25.458Âµs
   Collect: 1.334Âµs
   Total: 32.125Âµs (0.03ms)
   Rows: 1000
   Throughput: 31128404.67 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.041Âµs
   Execute: 26.583Âµs
   Collect: 1.667Âµs
   Total: 34.375Âµs (0.03ms)
   Rows: 1000
   Throughput: 29090909.09 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.708Âµs
   Execute: 21.958Âµs
   Collect: 1.583Âµs
   Total: 30.333Âµs (0.03ms)
   Rows: 1000
   Throughput: 32967395.25 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 4.875Âµs
   Execute: 17.917Âµs
   Collect: 1.291Âµs
   Total: 24.167Âµs (0.02ms)
   Rows: 1000
   Throughput: 41378739.60 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5Âµs
   Execute: 17.75Âµs
   Collect: 1.25Âµs
   Total: 24.083Âµs (0.02ms)
   Rows: 1000
   Throughput: 41523066.06 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.458Âµs
   Execute: 28.208Âµs
   Collect: 1.708Âµs
   Total: 35.5Âµs (0.04ms)
   Rows: 1000
   Throughput: 28169014.08 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.334Âµs
   Execute: 28Âµs
   Collect: 4.25Âµs
   Total: 38.708Âµs (0.04ms)
   Rows: 1000
   Throughput: 25834452.83 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.583Âµs
   Execute: 22.458Âµs
   Collect: 1.708Âµs
   Total: 30.917Âµs (0.03ms)
   Rows: 1000
   Throughput: 32344664.75 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.75Âµs
   Execute: 21.458Âµs
   Collect: 1.291Âµs
   Total: 29.625Âµs (0.03ms)
   Rows: 1000
   Throughput: 33755274.26 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 7.083Âµs
   Execute: 21.792Âµs
   Collect: 1.292Âµs
   Total: 30.25Âµs (0.03ms)
   Rows: 1000
   Throughput: 33057851.24 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.459Âµs
   Execute: 21.125Âµs
   Collect: 1.667Âµs
   Total: 29.375Âµs (0.03ms)
   Rows: 1000
   Throughput: 34042553.19 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 5.75Âµs
   Execute: 26.875Âµs
   Collect: 1.667Âµs
   Total: 34.375Âµs (0.03ms)
   Rows: 1000
   Throughput: 29090909.09 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 6.791Âµs
   Execute: 17.792Âµs
   Collect: 1.292Âµs
   Total: 25.875Âµs (0.03ms)
   Rows: 1000
   Throughput: 38647343.00 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=1000, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 1000 rows (from fragment slice [0, 1000))
ProjectOperator::next: Got batch with 1000 rows, 10 columns from input
ProjectOperator::next: SELECT * - returning all 10 columns
LimitOperator::next: Got batch with 1000 rows from input
LimitOperator::next: Remaining rows to return: 1000
LimitOperator::next: Returning batch with 1000 rows (total returned: 1000)
ExecutionEngine: Got batch with 1000 rows (total so far: 1000)
LimitOperator::next: rows_returned=1000, limit=1000, offset=0
LimitOperator::next: Already returned 1000 rows, limit is 1000, returning None
ExecutionEngine: Total row_count from batches: 1000 (calculated: 1000)
â±ï¸  Execution timing:
   Build: 4.75Âµs
   Execute: 18.584Âµs
   Collect: 1.334Âµs
   Total: 24.75Âµs (0.02ms)
   Rows: 1000
   Throughput: 40404040.40 rows/sec
  Run 1: 0.02679ms ... (avg of 5 runs: 0.03033ms)
  âœ“ Average: 0.03033ms | Rows: 1000

  ğŸ“‹ Hypergraph Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Year |Industry_... |Industry_... |Industry_... |       Units |Variable_... |Variable_... |Variable_... |       Value |Industry_...
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H01 |Total income |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |        2863 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H05 |Interest,... |Financial... |           6 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |           0 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H08 |Total exp... |Financial... |           C |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H09 |Interest ... |Financial... |        3327 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |          42 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H11 |Depreciation |Financial... |           9 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |         169 |ANZSIC06 ...
          2024 |     Level 1 |          AA |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         485 |ANZSIC06 ...
  ... (showing first 10 rows)


ğŸ”· PostgreSQL:
  Run 1: 2.31725ms ... (avg of 5 runs: 1.93737ms)
  âœ“ Average: 1.93737ms | Rows: 1000

  ğŸ“‹ PostgreSQL Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...
  ... (showing first 10 of 1000 rows)


ğŸ”· DuckDB:
  Run 1: 0.48317ms ... (avg of 5 runs: 0.47420ms)
  âœ“ Average: 0.47420ms | Rows: 1000

  ğŸ“‹ DuckDB Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1 |       col_2 |       col_3 |       col_4 |       col_5 |       col_6 |       col_7 |       col_8 |       col_9
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H01 |Total income |Financial... |      979594 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H04 |Sales, go... |Financial... |      838626 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H05 |Interest,... |Financial... |      112188 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H07 |Non-opera... |Financial... |       28781 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H08 |Total exp... |Financial... |      856960 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H09 |Interest ... |Financial... |       71493 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H10 |Indirect ... |Financial... |        8540 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H11 |Depreciation |Financial... |       32896 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H12 |Salaries ... |Financial... |      157616 |ANZSIC06 ...
          2024 |     Level 1 |       99999 |All indus... |Dollars (... |         H13 |Redundanc... |Financial... |         323 |ANZSIC06 ...
  ... (showing first 10 of 1000 rows)


ğŸ“Š Comparison:
  ğŸš€ Hypergraph Engine is 63.86978x FASTER than PostgreSQL
  ğŸš€ Hypergraph Engine is 15.63304x FASTER than DuckDB

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query 4: SELECT Year, Value FROM enterprise_survey LIMIT 100
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”· Hypergraph Engine:
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 11.459Âµs
   Execute: 95.708Âµs
   Collect: 1.25Âµs
   Total: 108.542Âµs (0.11ms)
   Rows: 100
   Throughput: 921302.35 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.208Âµs
   Execute: 24.292Âµs
   Collect: 1.292Âµs
   Total: 31.875Âµs (0.03ms)
   Rows: 100
   Throughput: 3137254.90 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.708Âµs
   Execute: 23.042Âµs
   Collect: 4.208Âµs
   Total: 33Âµs (0.03ms)
   Rows: 100
   Throughput: 3030303.03 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 7.291Âµs
   Execute: 29.084Âµs
   Collect: 1.209Âµs
   Total: 37.708Âµs (0.04ms)
   Rows: 100
   Throughput: 2651957.14 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.792Âµs
   Execute: 24.5Âµs
   Collect: 1.292Âµs
   Total: 31.667Âµs (0.03ms)
   Rows: 100
   Throughput: 3157861.50 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 4.792Âµs
   Execute: 39.25Âµs
   Collect: 1.708Âµs
   Total: 45.792Âµs (0.05ms)
   Rows: 100
   Throughput: 2183787.56 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.958Âµs
   Execute: 26.916Âµs
   Collect: 1.417Âµs
   Total: 34.375Âµs (0.03ms)
   Rows: 100
   Throughput: 2909090.91 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.709Âµs
   Execute: 22.375Âµs
   Collect: 1.333Âµs
   Total: 29.542Âµs (0.03ms)
   Rows: 100
   Throughput: 3385011.17 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.459Âµs
   Execute: 22.792Âµs
   Collect: 1.458Âµs
   Total: 29.75Âµs (0.03ms)
   Rows: 100
   Throughput: 3361344.54 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.375Âµs
   Execute: 30.042Âµs
   Collect: 1.291Âµs
   Total: 36.75Âµs (0.04ms)
   Rows: 100
   Throughput: 2721088.44 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.167Âµs
   Execute: 28.041Âµs
   Collect: 1.625Âµs
   Total: 35.959Âµs (0.04ms)
   Rows: 100
   Throughput: 2780944.97 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.333Âµs
   Execute: 22.792Âµs
   Collect: 1.334Âµs
   Total: 30.583Âµs (0.03ms)
   Rows: 100
   Throughput: 3269790.41 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 6.25Âµs
   Execute: 30.584Âµs
   Collect: 1.666Âµs
   Total: 38.583Âµs (0.04ms)
   Rows: 100
   Throughput: 2591815.05 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.042Âµs
   Execute: 28.625Âµs
   Collect: 1.292Âµs
   Total: 35.084Âµs (0.04ms)
   Rows: 100
   Throughput: 2850302.13 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.584Âµs
   Execute: 22.125Âµs
   Collect: 1.458Âµs
   Total: 29.25Âµs (0.03ms)
   Rows: 100
   Throughput: 3418803.42 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 4.833Âµs
   Execute: 24.5Âµs
   Collect: 1.25Âµs
   Total: 30.667Âµs (0.03ms)
   Rows: 100
   Throughput: 3260834.12 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.459Âµs
   Execute: 29.875Âµs
   Collect: 1.625Âµs
   Total: 37.042Âµs (0.04ms)
   Rows: 100
   Throughput: 2699638.25 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 4.875Âµs
   Execute: 22.209Âµs
   Collect: 1.25Âµs
   Total: 28.458Âµs (0.03ms)
   Rows: 100
   Throughput: 3513950.38 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.209Âµs
   Execute: 31.584Âµs
   Collect: 1.625Âµs
   Total: 38.5Âµs (0.04ms)
   Rows: 100
   Throughput: 2597402.60 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.833Âµs
   Execute: 23.667Âµs
   Collect: 1.417Âµs
   Total: 30.917Âµs (0.03ms)
   Rows: 100
   Throughput: 3234466.47 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 7.167Âµs
   Execute: 32.917Âµs
   Collect: 1.75Âµs
   Total: 41.917Âµs (0.04ms)
   Rows: 100
   Throughput: 2385666.91 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.5Âµs
   Execute: 27.958Âµs
   Collect: 1.417Âµs
   Total: 34.917Âµs (0.03ms)
   Rows: 100
   Throughput: 2863934.47 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5.375Âµs
   Execute: 22.459Âµs
   Collect: 1.375Âµs
   Total: 29.333Âµs (0.03ms)
   Rows: 100
   Throughput: 3409129.65 rows/sec
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))
ProjectOperator::next: Got batch with 100 rows, 10 columns from input
ProjectOperator::next: Projecting 2 columns: ["Year", "Value"]
ProjectOperator::next: Returning batch with 100 rows, 2 columns
LimitOperator::next: Got batch with 100 rows from input
LimitOperator::next: Remaining rows to return: 100
LimitOperator::next: Returning batch with 100 rows (total returned: 100)
ExecutionEngine: Got batch with 100 rows (total so far: 100)
LimitOperator::next: rows_returned=100, limit=100, offset=0
LimitOperator::next: Already returned 100 rows, limit is 100, returning None
ExecutionEngine: Total row_count from batches: 100 (calculated: 100)
â±ï¸  Execution timing:
   Build: 5Âµs
   Execute: 29.458Âµs
   Collect: 1.458Âµs
   Total: 36Âµs (0.04ms)
   Rows: 100
   Throughput: 2777777.78 rows/sec
  Run 1: 0.02954ms ... (avg of 5 runs: 0.03154ms)
  âœ“ Average: 0.03154ms | Rows: 100

  ğŸ“‹ Hypergraph Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Year |       Value
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |           C
          2024 |        2863
          2024 |           6
          2024 |           0
          2024 |           C
          2024 |        3327
          2024 |          42
          2024 |           9
          2024 |         169
          2024 |         485
  ... (showing first 10 rows)


ğŸ”· PostgreSQL:
  âœ— Error: db error (took 0.10829ms)
  âœ“ Average: 0.00000ms | Rows: 0

ğŸ”· DuckDB:
  Run 1: 0.24475ms ... (avg of 5 runs: 0.24463ms)
  âœ“ Average: 0.24463ms | Rows: 100

  ğŸ“‹ DuckDB Results (showing first 10 rows):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         col_0 |       col_1
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          2024 |      979594
          2024 |      838626
          2024 |      112188
          2024 |       28781
          2024 |      856960
          2024 |       71493
          2024 |        8540
          2024 |       32896
          2024 |      157616
          2024 |         323
  ... (showing first 10 of 100 rows)


ğŸ“Š Comparison:
  ğŸš€ Hypergraph Engine is 7.75584x FASTER than DuckDB

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query 5: SELECT * FROM enterprise_survey WHERE Year = 2024 LIMIT 100
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”· Hypergraph Engine:
ScanOperator: Found 10 columns with up to 1 fragments each for table 'enterprise_survey' (first fragment has 55620 rows)
LimitOperator::next: rows_returned=0, limit=100, offset=0
ScanOperator::next: Creating batch with 55620 rows, 10 columns (fragment 1/1)
ScanOperator::next: Created ExecutionBatch with 100 rows (from fragment slice [0, 100))

thread 'main' (683992) panicked at src/execution/simd_kernels.rs:36:31:
index out of bounds: the len is 100 but the index is 128
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
